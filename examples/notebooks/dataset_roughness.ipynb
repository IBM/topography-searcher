{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdf7b3df-f835-4cb8-941b-7410789832b9",
   "metadata": {},
   "source": [
    "# Dataset roughness computation\n",
    "\n",
    "In this notebook we show how to use TopSearch to compute the roughness of a given dataset. We use the energy landscape framework to compute the topographical mapping of the dataset for each pair of its features. From these weighted graphs we compute the average frustration metric, which is a good approximation for dataset roughness. We perform this analysis for several example molecular datasets and illustrate the correlation of frustration and model error. Therefore, we show that we are able to estimate the modellability of a particular representation before fitting a machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb93c6c-39f3-4891-bc39-a33af629d671",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "First we import topsearch, which contains all the functionality we need for this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5493a61-439c-4441-88c7-cce5d5a6ed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import topsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44eef9e-45eb-4a02-b31b-b6c0be484d5d",
   "metadata": {},
   "source": [
    "## Initialise classes\n",
    "\n",
    "Landscape generation requires several classes to be instantiated. We list each of them in turn here, and describe their functionality.\n",
    "First, we generate the potential class that calculates the function value and its derivatives when given a set of coordinates. In this example this class extracts a molecular dataset for the property of clearance in the microsome, as generated by Astra Zeneca, we perform an interpolation of this dataset with smoothness parameter 'smoothness', which is set to almost zero in order to exactly interpolate the known dataset. We extract n_data data points, and normalise both the response and all the features of the training data. Furthermore, we choose to flip the data to make it a minimisation problem for convenience. Finally, we specify a subset of features for which to consider "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65e395c-1157-4556-a730-f365ecaa581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_interpolation = topsearch.potential.MolecularInterpolation(mol_property='Clearance_Microsome_AZ',\n",
    "                                                               norm_response=True,\n",
    "                                                               norm_training=True,\n",
    "                                                               flip_data=True,\n",
    "                                                               n_data=500,\n",
    "                                                               smoothness=1e-5,\n",
    "                                                               feature_subset=True,\n",
    "                                                               chosen_features=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58b7952-87f3-4732-9ef3-6ed356021f86",
   "metadata": {},
   "source": [
    "Next we initialise the comparison class, which is responsible for determining the distance between points in feature space and determining if they are the same. We may generate repeated minima and transition states and the functions of this class will allow us to filter out repeats and only include unique stationary points. We are required to specify a distance_criterion and energy_criterion within which two minima and transition states are considered the same. The proportional_distance scales the distance_criterion to reflect the total range, in this case it is active resulting in the criterion taking any points within 5% of the feature space and within the energy_criterion as the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff976478-4838-46cb-9224-819070840de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparer = topsearch.similarity.NonAtomicSimilarity(potential=mol_interpolation,\n",
    "                                                    distance_criterion=0.05,\n",
    "                                                    energy_criterion=1e-2,\n",
    "                                                    proportional_distance=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7ba276-b4d9-4d0f-beff-0345a17b76af",
   "metadata": {},
   "source": [
    "We provide these two instances to the KineticTransitionNetwork class. This contains the networkx object in which all the minima and transition states are stored as a weighted graph. This class controls all access to the network and performs operations to extract information and analyse it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94780e0f-48e3-4efa-a848-99e457d8f0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ktn = topsearch.kinetic_transition_network.KineticTransitionNetwork(potential=mol_interpolation,\n",
    "                                                                    similarity=comparer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655eaf61-4758-41c8-bcd1-4573bc63a6d3",
   "metadata": {},
   "source": [
    "Additionally, we need a local minimiser as all these methods rely on locating local minima. Our local minimiser class provides a wrapper to the scipy box-constrained LBFGS implementation that is adapted to the different optimisation tasks we perform. We need to provide it the function that it minimises, along with the maximum number of steps it can take, the LBFGS history and gradient at which it has successfully converged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d327cd-45c4-455a-b613-aff57157db2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimiser = topsearch.minimisation.LBFGS(potential=mol_interpolation,\n",
    "                                         conv_crit=1e-6,\n",
    "                                         history_size=5,\n",
    "                                         n_steps=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd7730a-a1f6-4c21-a3c1-21e99b9424d7",
   "metadata": {},
   "source": [
    "Locating transition states requires a combination of single-ended and double-ended searches. Double-ended searches take two minima as input and attempt to find the lowest-valued path between them. Single-ended searches start from a single point and follow the eigenvector corresponding to the most negative eigenvalue until they converge to a transition state. These two searches are used in tandem, with an initial double-ended search, following by a single-ended search applied to each local maximum on the path. Here, we use the nudged elastic band as the double-ended search method. NudgedElasticBand contains the methods to produce an initial path and optimise it to minimise its overall value. We specify it using three parameters: force_constant - determines the tightness of the elastic band, this is updated within the computation, image density - this determines how many points the path is composed of (per unit distance), more points means better path (usually) as higher computational cost, max images - allows us to put a cut on the maximum number of images to limit the computational cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39cbed3-c07a-4d6d-b7ad-dfb0a4e1be7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nudged_elastic_band = \\\n",
    "    topsearch.double_ended_search.NudgedElasticBand(potential=mol_interpolation,\n",
    "                                                    minimiser=minimiser,\n",
    "                                                    force_constant=50.0,\n",
    "                                                    image_density=5.0,\n",
    "                                                    max_images=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76ed7cd-2986-41cc-8293-f48f60f35c0d",
   "metadata": {},
   "source": [
    "The single-ended search method is hybrid eigenvector-following. This class provides methods to take in a single point and provide the methods to converge it to the nearest transition state. We provide it with a convergence criterion, the gradient must be under this value to be considered converged to a stationary point. We also provide the allowed number of mode-following steps before it is considered a failed search for a transition state. Each transition state is connected to two minima by following the steepest-descent paths along the unique downhill direction and we specify the distance we move in the downhill direction before beginning a local minimisation using pushoff. Finally, we have some step sizes used in the mode-following to prevent the steps being too large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9869fb6a-28f2-4324-8b9b-b1c017f3f632",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_eigenvector_following = \\\n",
    "    topsearch.single_ended_search.HybridEigenvectorFollowing(potential=mol_interpolation,\n",
    "                                                             minimiser=minimiser,\n",
    "                                                             conv_crit=1e-4,\n",
    "                                                             ts_steps=100,\n",
    "                                                             pushoff=1e-1,\n",
    "                                                             max_uphill_step_size=0.5,\n",
    "                                                             positive_eigenvalue_step=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410c0969-2938-4ce6-8b87-b9c47a5e1f40",
   "metadata": {},
   "source": [
    "For global optimisation algorithms we need to be able to propose new structures from the existing ones. The efficiency of global optimisation relies on the proposal of good candidate positions. For molecular systems this is an involved problem with a lot of research invested into it. For the non-atomic system here the step-taking is much simpler, it can just be random perturbations. This class manages the perturbations to propose new states, it is given the maximum step size, max_displacement, and we specify that this distance should be measured as a proportion of the bounds range with proportional distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b5e17a-f822-4a33-b442-d8e67389130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_taking = topsearch.perturbations.NonAtomicPerturbation(potential=mol_interpolation,\n",
    "                                                            max_displacement=1.0,\n",
    "                                                            proportional_distance=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055ba991-65ed-4b28-b4c8-b75770f6ec71",
   "metadata": {},
   "source": [
    "Initialise the global optimisation class. The global optimisation algorithm is basin-hopping, which is provided with the step-taking class previously created. Basin-hopping steps around the surface performing local minimisations and subsequently accepting or rejecting the new local minima based on a Metropolis-like criterion. The BasinHopping class performs basin-hopping runs consisting of n_steps random perturbations and local minimisations, with a temperature specified to control the acceptance of new minima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c761bbc0-adcf-414a-b931-ccc02469730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = topsearch.global_optimisation.BasinHopping(ktn=ktn,\n",
    "                                                       minimiser=minimiser,\n",
    "                                                       n_steps=750,\n",
    "                                                       temperature=1.0,\n",
    "                                                       step_taking=step_taking)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536d3b42-d929-492d-b6d8-56faf7ba605b",
   "metadata": {},
   "source": [
    "Finally, we feed many of these objects into a NetworkSampling object that controls all the landscape generation. This object allows for simple calls to be made that perform the combination of algorithms for landscape generation. We pass it the global_optimiser and the transition state location methods. Transition state location simply requires two minima, and therefore, the sampling of the landscape is embarrassingly parallel. We have the option to use multiple processes to accelerate the landscape calculation. Here we decide to run on one CPU for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae62e04-d97d-43e2-93b6-e6f51d9f0287",
   "metadata": {},
   "outputs": [],
   "source": [
    "explorer = topsearch.exploration.NetworkSampling(ktn=ktn,\n",
    "                                                 minimiser=minimiser,\n",
    "                                                 global_optimiser=optimiser,\n",
    "                                                 single_ended_search=hybrid_eigenvector_following,\n",
    "                                                 double_ended_search=nudged_elastic_band,\n",
    "                                                 multiprocessing=True,\n",
    "                                                 n_processes=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d28603-fdf1-4aee-a369-fa0e3e8be398",
   "metadata": {},
   "source": [
    "## 1. Compute the topographical representation\n",
    "\n",
    "First, we will compute the topographical representation for each pair of features. We construct the interpolation for each "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b01231-4c3e-45b1-93f6-d4261e4b59a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f247fecb-0be1-4975-8640-7a0931ceaef5",
   "metadata": {},
   "source": [
    "We will then look through some of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7d4e67-72eb-46bd-aeae-9189857fb739",
   "metadata": {},
   "source": [
    "## 2. Compute the frustration metric for the structure-property relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c630ed-06bb-4a3c-b5f2-1cfe69881aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ktn.read_network()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a067b286-fbaa-44c1-b6c2-6fdbb2f279a0",
   "metadata": {},
   "source": [
    "## 3. Compute the regression error\n",
    "\n",
    "We perform regression of the same dataset using a simple neural network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
